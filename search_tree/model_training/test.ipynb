{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import chess\n",
    "import chess.engine\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, BatchNormalization, Dropout\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import load_model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.callbacks import ReduceLROnPlateau\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.callbacks import CSVLogger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data/chess_puzzles - Copy.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into two dataframes - one for 'best_lichess_move_vector' and one for 'best_stockfish_move_vector'\n",
    "# 'best_lichess_move_vector' is the move that lichess recommends\n",
    "# 'best_stockfish_move_vector' is the move that stockfish recommends\n",
    "\n",
    "data_lichess = data[['board','best_lichess_move_vector']]\n",
    "data_stockfish = data[['board','best_stockfish_move_vector']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to move and board\n",
    "data_lichess.columns = ['board','move']\n",
    "data_stockfish.columns = ['board','move']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data into training and testing data\n",
    "# 80% of data is used for training\n",
    "# 20% of data is used for testing\n",
    "\n",
    "data_lichess_train = data_lichess.sample(frac=0.8,random_state=200)\n",
    "data_lichess_test = data_lichess.drop(data_lichess_train.index)\n",
    "\n",
    "data_stockfish_train = data_stockfish.sample(frac=0.8,random_state=200)\n",
    "data_stockfish_test = data_stockfish.drop(data_stockfish_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all numpy arrays to lists from pandas dataframes\n",
    "# this is necessary because the neural network cannot handle numpy arrays\n",
    "lichess_train_X = data_lichess_train['board'].apply(lambda x: x.tolist()).tolist()\n",
    "lichess_train_Y = data_lichess_train['move'].apply(lambda x: x.tolist()).tolist()\n",
    "\n",
    "lichess_test_X = data_lichess_test['board'].apply(lambda x: x.tolist()).tolist()\n",
    "luchess_test_Y = data_lichess_test['move'].apply(lambda x: x.tolist()).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\Sadie\\anaconda3\\envs\\learn\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3457, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\Sadie\\AppData\\Local\\Temp\\ipykernel_18120\\1435384338.py\", line 3, in <module>\n",
      "    history_lichess, model_lichess = nn.model_cnn2(data=lichess_train_X, labels=lichess_train_Y, model_name='model_lichess.h5')\n",
      "  File \"c:\\Users\\Sadie\\Documents\\GitHub\\chessbot\\search_tree\\model_training\\neuralnet_chatgpt.py\", line 60, in model_cnn2\n",
      "    history = model.fit(data, labels, epochs=10, batch_size=32, validation_split=0.1)\n",
      "  File \"c:\\Users\\Sadie\\anaconda3\\envs\\learn\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"c:\\Users\\Sadie\\anaconda3\\envs\\learn\\lib\\site-packages\\keras\\engine\\data_adapter.py\", line 1664, in train_validation_split\n",
      "    raise ValueError(\n"
     ]
    }
   ],
   "source": [
    "import neuralnet_chatgpt as nn\n",
    "\n",
    "history_lichess, model_lichess = nn.model_cnn2(data=lichess_train_X, labels=lichess_train_Y, model_name='model_lichess.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
