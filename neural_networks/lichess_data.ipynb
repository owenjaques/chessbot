{"cells":[{"cell_type":"markdown","metadata":{"id":"lxs4B2ekzwoG"},"source":["# Training the model to run on Lichess data\n","## Some pre-requisites if running on Google Collab\n","If not running on Google collab do not run these next two cells!"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5569,"status":"ok","timestamp":1679025956750,"user":{"displayName":"Owen Jaques","userId":"14867164693067226317"},"user_tz":420},"id":"u8gnO_uq3ZBe","outputId":"3dba13aa-15b4-4d14-8cc5-d88d4636427d"},"outputs":[],"source":["# Install the only dependency not available from collab directly\n","!pip install chess\n","\n","# Get imported files from repo\n","!git clone -b lichess-neural-networks https://github.com/owenjaques/chessbot.git\n","!mv chessbot chessbot-repo\n","!mv chessbot-repo/neural_networks/chessbot .\n","!rm chessbot-repo -r"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":24942,"status":"ok","timestamp":1679025981613,"user":{"displayName":"Owen Jaques","userId":"14867164693067226317"},"user_tz":420},"id":"DJoqUIfm5Ory","outputId":"bafcb809-9070-4353-80f7-b57fb405d6ef"},"outputs":[],"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')\n","working_directory = '/content/gdrive/MyDrive/chessbot_weights/'\n","print(f'Saving to {working_directory}')"]},{"cell_type":"markdown","metadata":{"id":"8lTAAinwzOS8"},"source":["## If not running on Google Collab\n","Set the weights directory variable to wherever you would like data saved."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"n_EV6byQzOS_"},"outputs":[],"source":["!mkdir -p data\n","working_directory = './data/'"]},{"cell_type":"markdown","metadata":{"id":"cQHeVT0f1kgz"},"source":["## Get the data\n","This compression format is really nice, so you can cancel this cell whenever you want and all the games that were downloaded will be maintained. In my experience 300Mb gets well over 100,000 games."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12587,"status":"ok","timestamp":1679026954288,"user":{"displayName":"Owen Jaques","userId":"14867164693067226317"},"user_tz":420},"id":"tiexRHwp1kg2","outputId":"b6468c77-68ab-4a38-d644-dd569ed55f1b"},"outputs":[],"source":["!wget https://database.lichess.org/standard/lichess_db_standard_rated_2023-02.pgn.zst"]},{"cell_type":"markdown","metadata":{"id":"nddTHHyF1kg4"},"source":["## Decompress the Data"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15338,"status":"ok","timestamp":1679026970933,"user":{"displayName":"Owen Jaques","userId":"14867164693067226317"},"user_tz":420},"id":"ogpp8WbV1kg8","outputId":"50762397-18c8-4898-8658-678cbd3cd0b5"},"outputs":[],"source":["!apt install zstd\n","!pzstd -d lichess_db_standard_rated_2023-02.pgn.zst"]},{"cell_type":"markdown","metadata":{"id":"8XOUyCRl1kg_"},"source":["## Transform the Data\n","For this section we create a data generator which will play the games from disk then translate them into labelled model inputs which the model will train on."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1836,"status":"ok","timestamp":1679026002741,"user":{"displayName":"Owen Jaques","userId":"14867164693067226317"},"user_tz":420},"id":"7l0poAsDzOTc"},"outputs":[],"source":["import chess\n","import chess.pgn\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from tensorflow import keras\n","from collections import deque"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1679032943239,"user":{"displayName":"Owen Jaques","userId":"14867164693067226317"},"user_tz":420},"id":"p9c5M8uKIzr5"},"outputs":[],"source":["from chessbot.model_input import ModelInput\n","\n","class DataGenerator(keras.utils.Sequence):\n","    def __init__(self, batch_size, pgn_file, num_batches=128, name='training data', verbose=0):\n","        self.batch_size = batch_size\n","        self.num_batches = num_batches\n","        self.X_queue = deque()\n","        self.y_queue = deque()\n","        self.pgn = pgn_file\n","        self.n = batch_size * num_batches\n","        self.X = np.empty((self.n, 102))\n","        self.y = np.empty((self.n, 3), dtype=int)\n","        self.verbose = verbose\n","        self.name = name\n","        self.game_headers = []\n","        self.populate_Xy()\n","\n","    def populate_Xy(self):\n","        # Plays games from the dataset and populates X and y\n","        \n","        i = 0\n","        while i < self.n:\n","            game = chess.pgn.read_game(self.pgn)\n","            if game is None:\n","                raise Exception('DataGenerator: Out of data to read from disk.')\n","    \n","            # Only train on game played to completion, that were not draws, and that have evaluations\n","            next_node = game.next()\n","            if not (game.headers['Termination'] == 'Normal' and game.headers['Result'] in ['1-0', '0-1'] and next_node and next_node.eval() != None):\n","                continue\n","\n","            if game.headers in self.game_headers:\n","                raise Exception('Something has gone horribly wrong and we have a duplicate game.')\n","            self.game_headers.append(game.headers)\n","\n","            try:\n","                # Generate the data from the game\n","                board = game.board()\n","                for node in game.mainline():\n","                    board.push(node.move)\n","                    self.X[i] = (ModelInput(board).get_input())\n","                    eval = node.eval().white().score(mate_score=10000)\n","                    self.y[i] = [eval <= -125, -125 < eval < 125, eval >= 125]\n","                    i += 1\n","                    \n","                    if self.verbose > 0:\n","                        print(f'\\rGenerated {i}/{self.n} samples for {self.name}', end='')\n","            except:\n","                # There are a lot of reasons an exception could be thrown here, mostly stemming from bad data being parsed\n","                # from the pgn file. We just ignore these games and move on.\n","                pass\n","\n","        if self.verbose > 0:\n","            print(f'\\nNumber of losing positions: {np.sum(self.y[:, 0])}, Number of drawing positions: {np.sum(self.y[:, 1])}, Number of winning positions: {np.sum(self.y[:, 2])}')\n","\n","        # For regression\n","        # if self.verbose > 1:\n","        #     _, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n","        #     ax[0].hist(self.y, bins=50)\n","        #     ax[0].set_title(f'Labels for {self.name} (before normalising)')\n","        #     ax[0].set_xlabel('label (y)')\n","        #     ax[0].set_ylabel('no. of occurences in dataset')\n","\n","        # Threshold to remove outliers and increase distribution of data\n","        # threshold_boundary = 1500\n","        # self.y[self.y > threshold_boundary] = threshold_boundary\n","        # self.y[self.y < -threshold_boundary] = -threshold_boundary\n","\n","        # # Normalise in the range [0, 1]\n","        # self.y = (self.y - np.min(self.y)) / (np.max(self.y) - np.min(self.y))\n","\n","        # if self.verbose > 1:\n","        #     ax[1].hist(self.y, bins=50)\n","        #     ax[1].set_title(f'Labels for {self.name} (after normalising)')\n","        #     ax[1].set_xlabel('label (y)')\n","        #     ax[1].set_ylabel('no. of occurences in dataset')\n","        #     plt.show()\n","        \n","    def on_epoch_end(self):\n","        self.populate_Xy()\n","\n","    def __len__(self):\n","        return self.n\n","\n","    def __getitem__(self, idx):\n","        # Returns one batch of data\n","        batch_idx_start = idx * self.batch_size\n","        batch_idx_end = idx * (self.batch_size + 1)\n","        return self.X[batch_idx_start:batch_idx_end], self.y[batch_idx_start:batch_idx_end]"]},{"cell_type":"markdown","metadata":{"id":"4NoDAvLu3WvE"},"source":["## Our model\n","Set up your model being used here."]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":30,"status":"ok","timestamp":1679033494965,"user":{"displayName":"Owen Jaques","userId":"14867164693067226317"},"user_tz":420},"id":"lYMalYMGzwoT"},"outputs":[],"source":["model = keras.Sequential([\n","\tkeras.layers.Dense(512, activation='relu'),\n","\tkeras.layers.Dense(512, activation='relu'),\n","\tkeras.layers.Dense(3, activation='softmax')\n","])\n","\n","model.compile(\n","    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n","    loss='categorical_crossentropy',\n","\tmetrics=['accuracy']\n",")"]},{"attachments":{},"cell_type":"markdown","metadata":{"id":"8SR_Dpj1zwox"},"source":["## Training the model\n","This next cell trains the model on the training data, then saves it to disk. Note multiple calls to this cell have crashed the notebook before due to high RAM usages."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":108310,"status":"ok","timestamp":1679033205055,"user":{"displayName":"Owen Jaques","userId":"14867164693067226317"},"user_tz":420},"id":"pILp2Qq6Tw7v","outputId":"4e08e1f0-c5de-453a-b4dd-0893a98e0984"},"outputs":[],"source":["pgn_file = open('lichess_db_standard_rated_2023-02.pgn', 'r')\n","batch_size = 32\n","num_batches = 1024\n","\n","training_data = DataGenerator(batch_size, pgn_file, num_batches, verbose=2)\n","validation_data = DataGenerator(batch_size, pgn_file, int(num_batches*0.2), name='validation data', verbose=2)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":588},"executionInfo":{"elapsed":336502,"status":"error","timestamp":1679033850302,"user":{"displayName":"Owen Jaques","userId":"14867164693067226317"},"user_tz":420},"id":"Z_xQn9DMzwpC","outputId":"1287ef7d-f4d9-446a-cd33-928085fce834"},"outputs":[],"source":["early_stopping = keras.callbacks.EarlyStopping(\n","    monitor='val_loss',\n","    restore_best_weights=True,\n","    patience=20,\n","    verbose=1)\n","\n","reduce_lr = keras.callbacks.ReduceLROnPlateau(\n","    monitor='val_loss',\n","    factor=0.2,\n","    patience=10,\n","    min_lr=0.000000000000001,\n","    verbose=1)\n","\n","checkpoint = keras.callbacks.ModelCheckpoint(\n","    f'{working_directory}lichess_trained_model',\n","    monitor='val_loss',\n","    save_best_only=True)\n","\n","tensorboard = keras.callbacks.TensorBoard(\n","    log_dir=f'{working_directory}/logs',\n","    write_graph=True,\n","    write_images=True,\n","    histogram_freq=1)\n","\n","model.fit(\n","    training_data,\n","    epochs=128,\n","    shuffle=True,\n","    validation_data=validation_data,\n","    callbacks=[early_stopping, reduce_lr, checkpoint, tensorboard])"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Launch tensorboad"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BNOSv54_1LQa"},"outputs":[],"source":["%reload_ext tensorboard\n","%tensorboard --logdir /content/gdrive/MyDrive/chessbot_weights/logs/train"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Optionally load a previous model"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":2594,"status":"ok","timestamp":1679026098259,"user":{"displayName":"Owen Jaques","userId":"14867164693067226317"},"user_tz":420},"id":"b4WOshr4vnBH"},"outputs":[],"source":["model = keras.models.load_model(f'{working_directory}/lichess_trained_model')"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["### Confusion Matrix"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n","\n","y_pred = model.predict(validation_data.X)\n","y_pred = np.argmax(y_pred, axis=1)\n","y_true = np.argmax(validation_data.y, axis=1)\n","cm = confusion_matrix(y_true, y_pred)\n","\n","ax = sns.heatmap(cm, annot=True, fmt='d', xticklabels=['Losing', 'Drawing', 'Winning'], yticklabels=['Losing', 'Drawing', 'Winning'])\n","ax.set(xlabel='Predicted label', ylabel='True label')"]},{"cell_type":"markdown","metadata":{"id":"oUvGOIrU_bjf"},"source":["## Why not play a game after all that training?"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":3947,"status":"error","timestamp":1679032923171,"user":{"displayName":"Owen Jaques","userId":"14867164693067226317"},"user_tz":420},"id":"0UQyIKnj_h9E","outputId":"a57e7dd5-192f-4ec0-eaaa-f93e63011eca"},"outputs":[],"source":["import time\n","from IPython.display import clear_output\n","import chessbot.chessbot\n","from chessbot.chessbot import ChessBot\n","\n","def play_game(model, exploration_rate=0.0, should_visualise=False):\n","\twhite = ChessBot(model, chess.WHITE, exploration_rate)\n","\tblack = ChessBot(model, chess.BLACK, exploration_rate)\n","\n","\tboard = chess.Board()\n","\n","\tif should_visualise:\n","\t\tdisplay(board)\n","\n","\twhile not board.is_game_over(claim_draw=True):\n","\t\tboard.push(black.move(board) if board.turn == chess.BLACK else white.move(board))\n","\n","\t\tif should_visualise:\n","\t\t\ttime.sleep(1)\n","\t\t\tclear_output(wait=True)\n","\t\t\tdisplay(board)\n","\n","\treturn board.outcome(claim_draw=True).result()\n"," \n","play_game(model, should_visualise=True)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1T6cscqP9Se0J8sa5pmQ1tAQhOtJyIxWd","timestamp":1679015509793}]},"gpuClass":"standard","kernelspec":{"display_name":"env","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.6"}},"nbformat":4,"nbformat_minor":0}
