{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Maker\n",
        "plays random games labels them then saves the data so a model can be trained on it later. The idea was to save time on the first 10000 or games by saving fully random games then training. Does not implement piece values correctly now and models didnt train well on this data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "8P-Jlb25zwo1",
        "outputId": "985fd8c5-0af4-40a4-b502-5ae56a5f94db"
      },
      "outputs": [],
      "source": [
        "import chess\n",
        "import numpy as np\n",
        "import random\n",
        "from IPython.display import clear_output\n",
        "from chessbot.chessbot import ChessBot\n",
        "from chessbot.model_input import ModelInput\n",
        "\n",
        "def move(board):\n",
        "        moves = list(board.legal_moves)\n",
        "        move = random.choice(moves)\n",
        "        \n",
        "        return move\n",
        "\n",
        "\n",
        "def get_piece_values(board):\n",
        "\treward = 0\n",
        "\tpiece_map = board.piece_map()\n",
        "\tfor _, piece in piece_map.items():\n",
        "\t\tcolor = 1 if piece.color else -1\n",
        "\n",
        "\n",
        "\t\tif piece.piece_type == chess.ROOK:\n",
        "\t\t\treward += 5*color\n",
        "\t\telif piece.piece_type == chess.BISHOP or piece.piece_type == chess.KNIGHT:\n",
        "\t\t\treward += 3*color\n",
        "\t\telif piece.piece_type == chess.QUEEN:\n",
        "\t\t\treward += 8*color\n",
        "\t\telif piece.piece_type == chess.PAWN:\n",
        "\t\t\treward += 1*color\n",
        "\t\tr = reward/38 if (abs(reward/38))<1 else (reward/abs(reward))\n",
        "\treturn r\n",
        "\n",
        "def play_game():\n",
        "\tmoves = []\n",
        "\treward = []\n",
        "\tboard = chess.Board()\n",
        "\twhile not board.is_game_over(claim_draw=True):\n",
        "\t\tm = move(board)\n",
        "\t\tboard.push(m)\n",
        "\t\tmoves.append(ModelInput(board).get_input())\n",
        "\t\treward.append(get_piece_values(board))\n",
        "\n",
        "\tresult = board.outcome(claim_draw=True).result()\n",
        "\n",
        "\n",
        "\t# Blend the moves into a single array with alternating elements\n",
        "\tX = np.array(moves)\n",
        "\ty = np.array(reward)\n",
        "\t# Set the label for the last move to 1, representing a winning move, then\n",
        "\t# discount the rest as they led to a win but should not be rewarded as heavily\n",
        "\tdiscount_factor = 0.98\n",
        "\tif result != '1/2-1/2':\n",
        "\t\t# If black won flip the labels since our model evaluates white's position\n",
        "\t\tfor i in range(5,0,-1):\n",
        "\t\t\tif result == '1-0':\n",
        "\t\t\t\ty[len(y)-i] = 1*discount_factor**(i-1)\n",
        "\t\t\telif result == '0-1':\n",
        "\t\t\t\ty[len(y)-i] = -1*discount_factor**(i-1)\n",
        "\n",
        "\n",
        "\n",
        "\t# Scale the labels to be between 0 and 1 instead of -1 and 1\n",
        "\ty = (y + 1) / 2\n",
        "\n",
        "\treturn result, X, y"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TODO\n",
        "\n",
        "Fix so it uses the piece values labeling scheme and alter to save both wins and draws"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "vXbLcDWdzwo-",
        "outputId": "8f82677e-903f-48bc-8134-a208203d652e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Wins: 10000/10000 Total games: 66245"
          ]
        }
      ],
      "source": [
        "from IPython.display import clear_output\n",
        "\n",
        "results = []\n",
        "white_wins = 0\n",
        "black_wins = 0\n",
        "draws = 0\n",
        "\n",
        "X_all = None\n",
        "y_all = None\n",
        "\n",
        "while (white_wins+black_wins)<=10000:\n",
        "\tprint(f'\\rWins: {white_wins + black_wins}/10000 Total games: {white_wins+black_wins+draws}', end='')\n",
        "\tresult, X, y = play_game()\n",
        "\tresults.append(result)\n",
        "\n",
        "\tif X is not None and y is not None:\n",
        "\t\tif X_all is None:\n",
        "\t\t\tX_all = X\n",
        "\t\t\ty_all = y\n",
        "\t\telse:\n",
        "\t\t\tX_all = np.concatenate((X_all, X))\n",
        "\t\t\ty_all = np.concatenate((y_all, y))\n",
        "\n",
        "\tif result == '1-0':\n",
        "\t\twhite_wins += 1\n",
        "\tif result == '0-1':\n",
        "\t\tblack_wins += 1\n",
        "\tif result == '1/2-1/2':\n",
        "\t\tdraws += 1\n",
        "\t\n",
        "\n",
        "# Save the training data \n",
        "np.savez_compressed(f'chessbot_wins_data/{len(X_all)}_moves.npz', X=X_all, y=y_all)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
