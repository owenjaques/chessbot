{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxs4B2ekzwoG"
      },
      "source": [
        "# Neural Network Models\n",
        "Using the labelled Lichess data, this notebook will attempt to find a neural network which can fit that labelled data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Twp1klKKTEj3"
      },
      "source": [
        "## Pre-requisites"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t5dmXeDrTEj9"
      },
      "source": [
        "### If running on Google Collab\n",
        "If not running on Google collab do not run these next two cells!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8gnO_uq3ZBe",
        "outputId": "b957382e-81be-47bb-cd2e-256ba71e6e7f"
      },
      "outputs": [],
      "source": [
        "# Install the only dependency not available from collab directly\n",
        "!pip install chess\n",
        "\n",
        "# Get imported files from repo\n",
        "!git clone -b lichess-neural-networks https://github.com/owenjaques/chessbot.git\n",
        "!mv chessbot chessbot-repo\n",
        "!mv chessbot-repo/neural_networks/chessbot .\n",
        "!rm chessbot-repo -r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJoqUIfm5Ory",
        "outputId": "6f370989-f86d-4026-9eaf-b0a2a15c5fe6"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "working_directory = '/content/gdrive/MyDrive/chessbot_weights/'\n",
        "data_directory = working_directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8lTAAinwzOS8"
      },
      "source": [
        "### If not running on Google Collab\n",
        "Set the weights directory variable to wherever you would like data saved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n_EV6byQzOS_"
      },
      "outputs": [],
      "source": [
        "!mkdir -p bin\n",
        "working_directory = './bin'\n",
        "data_directory = '../pre_processing/data'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ut9n2VzSTEkg"
      },
      "source": [
        "## Load the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7l0poAsDzOTc"
      },
      "outputs": [],
      "source": [
        "import chess\n",
        "import chess.pgn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow import keras\n",
        "import math\n",
        "from chessbot import modelinput"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjATcT3mTEkr"
      },
      "source": [
        "### Data generator For Keras"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9c5M8uKIzr5"
      },
      "outputs": [],
      "source": [
        "class DataGenerator(keras.utils.Sequence):\n",
        "    def __init__(self, data_file, input_generator, batch_size=32, pre_process=True, save_file=None):\n",
        "        self.batch_size = batch_size\n",
        "        data = np.load(data_file, allow_pickle=True)\n",
        "        self.y = data['y']\n",
        "        self.n = len(self.y)\n",
        "\n",
        "        if pre_process:\n",
        "            self.X = np.empty((len(data['X']), input_generator.input_length()))\n",
        "            for i in range(self.n):\n",
        "                print(f'\\rPre-processing input {i}/{self.n}...', end='')\n",
        "                self.X[i] = input_generator.get_input_from_fen(data['X'][i])\n",
        "            \n",
        "            if save_file != None:\n",
        "                print('Saving X, y...')\n",
        "                np.savez_compressed(save_file, X=X, y=y)\n",
        "        else:\n",
        "            self.X = data['X']\n",
        "\n",
        "    def __len__(self):\n",
        "        return math.ceil(len(self.x) / self.batch_size)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Returns one batch of data\n",
        "        low = idx * self.batch_size\n",
        "        high = np.min(low + self.batch_size, self.n)\n",
        "        return self.X[low:high], self.y[low:high]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ivk-Ec-jTEk7"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-tv7B_6nJgd"
      },
      "source": [
        "### Regression Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OwfCqFHkTElA",
        "outputId": "64610234-1047-466b-de28-179ae7da29eb"
      },
      "outputs": [],
      "source": [
        "# Data generators for training the model\n",
        "training_data = DataGenerator(data_directory + '/training_set.npz', modelinput.ModelInput('positions'), save_file=data_directory + '/positions_training_set.npz')\n",
        "validation_data = DataGenerator(data_directory + '/validation_set.npz', modelinput.ModelInput('positions'), save_file=data_directory + '/positions_validation_set.npz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k4x0OtsVnMMr"
      },
      "outputs": [],
      "source": [
        "# The actual model\n",
        "model = keras.Sequential([\n",
        "\tkeras.layers.Dense(512, activation='relu'),\n",
        "\tkeras.layers.Dense(512, activation='relu'),\n",
        "\tkeras.layers.Dense(512, activation='relu'),\n",
        "\tkeras.layers.Dense(1)\n",
        "])\n",
        "\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='mse',\n",
        "\tmetrics=[keras.metrics.MeanAbsoluteError()]\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8SR_Dpj1zwox"
      },
      "source": [
        "## Training a Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_xQn9DMzwpC"
      },
      "outputs": [],
      "source": [
        "early_stopping = keras.callbacks.EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    restore_best_weights=True,\n",
        "    patience=5,\n",
        "    verbose=1)\n",
        "\n",
        "reduce_lr = keras.callbacks.ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=1,\n",
        "    min_lr=0.00000000000001,\n",
        "    verbose=1)\n",
        "\n",
        "checkpoint = keras.callbacks.ModelCheckpoint(\n",
        "    f'{working_directory}/model',\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True)\n",
        "\n",
        "tensorboard = keras.callbacks.TensorBoard(\n",
        "    log_dir=f'{working_directory}/logs',\n",
        "    write_graph=True,\n",
        "    write_images=True,\n",
        "    histogram_freq=1)\n",
        "\n",
        "model.fit(\n",
        "    training_data\n",
        "    epochs=128,\n",
        "    validation_data=validation_data,\n",
        "    shuffle=True,\n",
        "    callbacks=[early_stopping, reduce_lr, checkpoint, tensorboard])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhP-NlZFTElN"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMqv5oliZ-Zr"
      },
      "source": [
        "### Optionally load a previous model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4WOshr4vnBH"
      },
      "outputs": [],
      "source": [
        "model = keras.models.load_model(f'{working_directory}/model')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2JWZP_FZ-Zu"
      },
      "source": [
        "### Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DOC_EW2JZ-Zw"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "y_pred = model.predict(validation_data.X)\n",
        "y_pred = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(validation_data.y, axis=1)\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "ax = sns.heatmap(cm, annot=True, fmt='d', xticklabels=['Losing', 'Drawing', 'Winning'], yticklabels=['Losing', 'Drawing', 'Winning'])\n",
        "ax.set(xlabel='Predicted label', ylabel='True label')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL5FptVDqf79"
      },
      "source": [
        "### Histograms and predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3xb9RhKoqfA9"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Since at the end of the epoch the validation data is refreshed,\n",
        "# validation_data actually holds new data at the end of training\n",
        "evaluation = model.evaluate(validation_data)\n",
        "predictions = model.predict(validation_data[0])\n",
        "\n",
        "_, ax = plt.subplots(nrows=1, ncols=2, figsize=(12, 6))\n",
        "ax[0].hist(predictions, bins=50)\n",
        "ax[0].set_title(f'Predicted labels')\n",
        "ax[0].set_xlabel('label (y)')\n",
        "ax[0].set_ylabel('no. of occurences in dataset')\n",
        "ax[1].hist(validation_data[1], bins=50)\n",
        "ax[1].set_title(f'Actual labels')\n",
        "ax[1].set_xlabel('label (y)')\n",
        "ax[1].set_ylabel('no. of occurences in dataset')\n",
        "plt.show()\n",
        "\n",
        "# Bin the data into continuous intervals, then plot a confusion matrix\n",
        "predictions_binned = np.digitize(predictions, bins=np.linspace(0, 1, 10))\n",
        "y_binned = np.digitize(validation_data[1], bins=np.linspace(0, 1, 10))\n",
        "cm = confusion_matrix(y_binned, predictions_binned)\n",
        "ax = sns.heatmap(cm, annot=True, fmt='d')\n",
        "ax.set(xlabel='Predicted label', ylabel='True label')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oUvGOIrU_bjf"
      },
      "source": [
        "## Why not play a game after all that training?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UQyIKnj_h9E"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "from IPython.display import clear_output\n",
        "import chessbot.chessbot\n",
        "import importlib\n",
        "importlib.reload(chessbot.chessbot)\n",
        "from chessbot.chessbot import ChessBot\n",
        "\n",
        "def play_game(model, exploration_rate=0.0, should_visualise=False):\n",
        "\twhite = ChessBot(model, chess.WHITE, exploration_rate)\\\n",
        "\tboard = chess.Board()\n",
        "\n",
        "\tif should_visualise:\n",
        "\t\tdisplay(board)\n",
        "\n",
        "\twhile not board.is_game_over(claim_draw=True):\n",
        "\t\tboard.push(chess.Move.from_uci(input()) if board.turn == chess.BLACK else white.move(board))\n",
        "\n",
        "\t\tif should_visualise:\n",
        "\t\t\ttime.sleep(1)\n",
        "\t\t\tclear_output(wait=True)\n",
        "\t\t\tdisplay(board)\n",
        "\n",
        "\treturn board.outcome(claim_draw=True).result()\n",
        " \n",
        "play_game(model, should_visualise=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
